<!DOCTYPE HTML>
<html>
  <head>
    <!-- Google analytics tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-STGLQW4BJX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-STGLQW4BJX');
    </script>

    <!-- Title -->
    <title>Hai Zhang</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1000">

    <!-- Preload resources -->
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js" as="script">
    <link rel="preload" href="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js" as="script">

    <!-- Custom Style -->
    <link rel="stylesheet" href="style.css">

    <!-- Google Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Noto+Serif+SC:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Baloo+2:wght@400..800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <style>
      body {
        visibility: hidden;
      }
      .pdfContainer {
        width: 1000px;
        height: 600px;
        border: none;
      }
      .errorMessage {
        display: none;
        color: red;
        font-size: 20px;
      }
      .wechatModal.visible {
        display: block;
      }
      .accept-effect {
        position: absolute;
        font-size: 18px;
        font-weight: bold;
        color: rgb(234, 4, 12);
        transform: translate(-50%, -50%);
        animation: accept-animation 1s ease-out forwards;
        pointer-events: none;
        z-index: 1000;
      }
      @keyframes accept-animation {
        0% {
          opacity: 1;
          transform: translate(-50%, -50%) scale(1);
        }
        100% {
          opacity: 0;
          transform: translate(-50%, -150%) scale(1.5);
        }
      }
      /* Ensure only filtered items are visible */
      .grid .list-item {
        display: none;
      }
      .grid .list-item.isotope-item {
        display: block;
      }
    </style>
  </head>

  <body id="body">
    <div id="main">
      <!-- Intro section remains the same -->
      <div id="intro">
        <div id="intro-image">
          <img src="https://ik.imagekit.io/xxyvnpkee/profile.jpg?updatedAt=1755411235077">
        </div>
        <div id="intro-text">
          <h1>  <b> Hai </b>  <b> Zhang </b> | <span class="chinese-text"> 张 海 </span></h1>
          <p>
            Hi there!  
            I'm a first-year PhD student at <a target="_blank" href="https://mmlab.hk/">The Multimedia Laboratory (MMLab)</a> of <a target="_blank" href="https://www.hku.hk/">The University of Hong Kong</a>, jointly supervised by <a target="_blank" href="https://lihongyang.info/">Prof. Hongyang Li</a> and <a target="_blank" href="https://repository.hku.hk/cris/rp/rp02460">Prof. Fu Zhang</a>.
            Prior to this, 
            I earned both my Master's and Bachelor's degrees in Computer Science and Technology from <a target="_blank" href="https://cs.tongji.edu.cn/index.htm">Tongji University</a>, where I had the privilege of being supervised by <a target="_blank" href="http://cs1.tongji.edu.cn/~junqiao/">Prof. Junqiao Zhao</a>.
            <br>
            My research interests focus on general reinforcement learning and its applications in embodied intelligence, i.e. robotic manipulation, humanoid locomotion 🤖.
            I firmly believe that reinforcement learning holds significant promise as a pivotal pathway toward achieving Artificial General Intelligence.
            <br>
            Previously, I was fortunate to collaborate with <a target="_blank" href="https://lanqingli1993.github.io/">Prof. Lanqing Li</a> and <a target="_blank" href="https://www.cse.cuhk.edu.hk/~pheng/">Prof. Pheng Ann Heng</a> at The Chinese University of Hong Kong.
            Currently, I'm working closely with <a target="_blank" href="https://alvinwen428.github.io/">Dr. Chuan Wen</a> and <a target="_blank" href="https://people.iiis.tsinghua.edu.cn/~gaoyang/yang-gao.weebly.com/index.html">Prof. Yang Gao</a> at Tsinghua University to explore the generalization ability towards general robotic manipulation.
            <br>
            I'm always open to collaborations on reinforcement learning / robotics-related projects! Feel free to reach out —— I'd love to connect!👋. 
            <br><br>

            <a target="_blank" href="https://github.com/betray12138" style="color: #000000;"><i style="font-size:20px" class="fab">&#xf09b;</i> Github</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a target="_blank" href="https://www.zhihu.com/people/betray12138" style="color: #4185F4; font-size:17px"> <img src="https://ik.imagekit.io/xxyvnpkee/icon_zhihu.png?updatedAt=1755411231218" alt="", width="3%" /> Zhi Hu</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a target="_blank" href="https://scholar.google.com/citations?user=YHqAzxUAAAAJ&hl=zh-CN" style="color: #4185F4; font-size:17px"><i class="fa-brands fa-google-scholar"></i> Google Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="mailto:hai.zhang@connect.hku.hk" style="color: #070707e7; text-decoration: none;"><i class="fa-solid fa-envelope" style="color: #9f9f9f;"></i> hai.zhang@connect.hku.hk </a>
            

          <br><br>
          </p>
        </div>

      </div>

      <div id="filters" class="button-group">
        <button class="button is-checked" id="experienceButton" data-filter=".experience"><span>Experience</span></button>
        <!-- <button class="button" id="talkButton" data-filter=".talk"><span>Talks</span></button> -->
        <button class="button" id="researchButton" data-filter=".publication"><span>Publications</span></button>
        <button class="button" data-filter=".project"><span>Projects</span></button>
        <button class="button" data-filter=".cv"><span>CV</span></button>
      </div>

      <div class="grid">
        <!-- Experience -->
        <div class="list-item experience" data-category="experience">
          <p>
            <img src="https://ik.imagekit.io/xxyvnpkee/iiis.png?updatedAt=1755411231874" 
              style="float: right; margin-right: 20px; ; width: 280px; height: 120px;">
            <img src="https://ik.imagekit.io/xxyvnpkee/qizhi.png?updatedAt=1755411235433" 
              style="float: right; margin-right: 30px; margin-top: 30px ; width: 240px; height: 60px;">
          </p>
          <ul style="margin:0 0 20px;list-style-type:none;">
            <li>
              <autocolor>Research Intern, 2024.06~current</autocolor>
            </li>
            <div style="height: 20px;"></div>
            <li>
              <autocolor>Research Topic: VLA-Based General Manipulation </autocolor>
            </li>
            <div style="height: 20px;"></div>
            <li>
              <autocolor>Supervisor: <a target="_blank" href="https://people.iiis.tsinghua.edu.cn/~gaoyang/yang-gao.weebly.com/index.html">Prof. Yang Gao</a></autocolor>
            </li>
          </ul>     
  
          <div style="height: 80px;"></div>
          
          <p>
            <img src="https://ik.imagekit.io/xxyvnpkee/cuhk.png?updatedAt=1755411231262" 
              style="float: right; margin-right: 20px; ; width: 300px; height: 60px;">
            <img src="https://ik.imagekit.io/xxyvnpkee/zhejianglab.png?updatedAt=1755411239142" 
              style="float: right; margin-right: 40px; ; width: 140px; height: 60px;">
          </p>
          <ul style="margin:0 0 20px;list-style-type:none;">
            <li>
              <autocolor>Research Intern, 2023.07~2024.05</autocolor>
            </li>
            <div style="height: 20px;"></div>
            <li>
              <autocolor>Research Topic: Offline Meta Reinforcement Learning </autocolor>
            </li>
            <div style="height: 20px;"></div>
            <li>
              <autocolor>Supervisor: <a target="_blank" href="https://lanqingli1993.github.io/">Prof. Lanqing Li</a> and <a target="_blank" href="https://www.cse.cuhk.edu.hk/~pheng/">Prof. Pheng Ann Heng</a></autocolor>
            </li>
          </ul>     
          
        </div>

        <!-- Talks -->
        <!-- <div class="list-item talk" data-category="talk">
          <p>
            <img src="https://ik.imagekit.io/xxyvnpkee/cohere_lab.png?updatedAt=1755411231136" 
              style="float: right; margin-right: 20px; ; width: 360px; height: 96px;">
          </p>
          <ul style="margin:0 0 20px;list-style-type:none;">
            <li>
              <autocolor>Invited Guest Speaker @ <a target="_blank" href="https://cohere.com/research">Cohere Labs Community</a> </autocolor>
            </li>
            <div style="height: 20px;"></div>
            <li>
              <autocolor>Topic: <a target="_blank" href=""> Why offline meta reinforcement learning ? </a></autocolor>
            </li>
          </ul>     
          
        </div> -->

        <!-- Publications -->
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/astro.png?updatedAt=1755415475329" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="">ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts</a></h3>
            <p>
                Hang Yu, Di Zhang, Qiwei Du, Yanping Zhao, <u>Hai Zhang</u>, Guang Chen, Junqiao Zhao†, Eduardo E. Veas†
                <br><i>Under Review</i><br>
              
                <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> TL;DR: 
                  We propose ASTRO, a data augmentation framework that generates distributionally novel and dynamics-consistent trajectories for offline RL. 
                  ASTRO first learns a temporal-distance representation to identify distinct and dynamically plausible stitch targets. 
                  We then employ a dynamics-guided diffusion stitch planner via extrapolation discrepancies, defined as the gap between predicted and actual observations, 
                  to adaptively stitch trajectories through model-based rollouts.
                  
                  <br> <a target="_blank" href="">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="">Code</a>
                  <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;</span>
                        <iframe class="pdfContainer" src="files/RETRO_Poster.pdf#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                        <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                    </div>
                  </div>
                  </button>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a target="_blank" href="">Website</a> -->
            </p>
          </div>
        </div>
        
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="https://dinomini00.github.io/KineDex/" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/kinedex.png?updatedAt=1755411231247" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="https://dinomini00.github.io/KineDex/">KineDex: Learning Tactile-Informed Visuomotor Policies via Kinesthetic Teaching for Dexterous Manipulation</a></h3>
            <p>
                Di Zhang, Chengbo Yuan, Chuan Wen, <u>Hai Zhang</u>, Junqiao Zhao, Yang Gao†
                <font color="49bf9"><br><i>Conference on Robot Learning (CORL) 2025</i><br> </font>
                <font color="orange"><i>&#9733; Spotlight Presentation &#9733;</i></font><br>
              
                <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> TL;DR: 
                  We propose KineDex, a hand-over-hand kinesthetic teaching paradigm in which the operator's motion is directly transferred to the dexterous hand, 
                  enabling the collection of physically grounded demonstrations enriched with accurate tactile feedback.
                  KineDex can complete severely challenging tasks such as squeezing toothpaste onto a toothbrush, which require precise multi-finger coordination and stable force regulation.
                  KineDex collects data over twice as fast as teleoperation across two tasks of varying difficulty, while maintaining a near-100% success rate, compared to under 50% for teleoperation.
                  
                  <br> <a target="_blank" href="https://arxiv.org/abs/2505.01974">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://github.com/DinoMini00/KineDex_code">Code</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;</span>
                        <iframe class="pdfContainer" src="https://ik.imagekit.io/xxyvnpkee/CORL_2025_KineDex_Poster.pdf?updatedAt=1759478415435#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                        <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                    </div>
                  </div>
                  </button>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a target="_blank" href="https://dinomini00.github.io/KineDex/">Website</a>
            </p>
          </div>
        </div>
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/certain.png?updatedAt=1755411231355" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="">CERTAIN: Context Uncertainty-aware One-Shot Adaptation for Context-based Offline Meta Reinforcement Learning</a></h3>
            <p>
                Hongtu Zhou*, Ruiling Yang*, Yakun Zhu, Haoqi Zhao, <u>Hai Zhang</u>, Di Zhang, Junqiao Zhao†, Chen Ye, Changjun Jiang 
                <font color="49bf9"><br><i>International Conference on Machine Learning (ICML) 2025</i><br> </font>
              
                <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> TL;DR: 
                  We propose CERTAIN to tackle context ambiguity and OOD issues in one-shot adaptation for COMRL by leveraging uncertainty-aware task representation learning and context collection. 
                  Build upon heteroscedastic-like uncertainty estimation, our method can identify unreliable contexts and then lead to more robust policies.
                  
                  <br> <a target="_blank" href="">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://github.com/tiev-tongji/Certain">Code</a>
                  <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;</span>
                        <iframe class="pdfContainer" src="files/RETRO_Poster.pdf#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                        <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                    </div>
                  </div>
                  </button> -->
            </p>
          </div>
        </div>
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="https://openreview.net/forum?id=Cr1XlGBGVm" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/scrutinize.png?updatedAt=1755411235483" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="https://openreview.net/forum?id=Cr1XlGBGVm">Scrutinize What We Ignore: Reining In Task Representation Shift Of Context-Based Offline Meta Reinforcement Learning</a></h3>
            <p>
                <u>Hai Zhang</u>, Boyuan Zheng, Tianying Ji, Jinhang Liu, Anqi Guo, Junqiao Zhao†, Lanqing Li†
                <font color="49bf9"><br><i>International Conference on Learning Representations (ICLR) 2025</i><br></font>
                <font color="orange"><i>&#9733;  (Score: 6 6 8 8; top 5%) &#9733;</i></font><br>
              
                <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> TL;DR: 
                  We unify the training scheme commonly used in COMRL with the general RL objective, filling the gap between intuition and theoretical justification. 
                  We identify the new issue called task representation shift and theoretically demonstrate that by reining in the previously ignored task representation shift, it is possible to achieve monotonic performance improvements.
                  <br> <a target="_blank" href="https://openreview.net/forum?id=Cr1XlGBGVm">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://github.com/betray12138/Task-Representation-Shift">Code</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;</span>
                        <iframe class="pdfContainer" src="https://ik.imagekit.io/xxyvnpkee/RETRO_Poster.pdf?updatedAt=1755411081697#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                        <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                    </div>
                  </div>
                  </button>
            </p>
          </div>
        </div>
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="https://neurips.cc/virtual/2024/poster/95247" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/unicorn.png?updatedAt=1755411236165" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="https://neurips.cc/virtual/2024/poster/95247">Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning</a></h3>
            <p>
                Lanqing Li*, <u>Hai Zhang *</u>, Xinyu Zhang, Shatong Zhu, Junqiao Zhao†, Pheng-Ann Heng
                <font color="49bf9"><br><i>Annual Conference on Neural Information Processing Systems (NeurIPS) 2024</i><br> </font>
                <font color="orange"><i>&#9733; Spotlight Presentation (Score: 7 7 8; top 1%) &#9733;</i></font><br>
                <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> 
                  TL;DR: We propose a novel information theoretic framework of the context-based offline meta-RL paradigm, 
                  which unifies the mainstream COMRL methods, then leads to a general and state-of-the-art algorithm called UNICORN,
                  exhibiting remarkable generalization across a broad spectrum of RL benchmarks, context shift scenarios, data qualities and deep learning architectures. </font>
                  <!-- <br> <a target="_blank" href="https://openreview.net/pdf?id=QFUsZvw9mx">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://github.com/betray12138/UNICORN">Code</a>&nbsp;&nbsp;&nbsp;&bull;&nbsp;  -->
                  <br> <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/8a30aba6514b56d02976f49797f6338a-Abstract-Conference.html">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://github.com/betray12138/UNICORN">Code</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;</span>
                        <iframe class="pdfContainer" src="https://ik.imagekit.io/xxyvnpkee/unicorn_Poster.pdf?updatedAt=1755411078789#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                        <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                    </div>
                  </div>
                  </button>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a target="_blank" href="https://mp.weixin.qq.com/s/q7ecEiv5cPEwWyAvwfo_ig">Overview</a>
            </p>
          </div>
        </div>
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/SMG.png?updatedAt=1755411236287" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="https://openreview.net/pdf?id=wz2KvvEk44">Focus On What Matters: Separated Models For Visual-Based RL Generalization</a></h3>
            <p>
              Di Zhang, Bowen Lv, <u>Hai Zhang</u>, Feifan Yang, Junqiao Zhao†, Hang Yu, Chang Huang, Hongtu Zhou, Chen Ye, Changjun Jiang<br>
              <font color="49bf9"><i>Annual Conference on Neural Information Processing Systems (NeurIPS) 2024</i><br></font>
              <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> 
                TL;DR: We propose SMG, which utilizes a reconstruction-based auxiliary task to extract task-relevant representations from visual observations 
                and further strengths the generalization ability of RL agents with the help of two consistency losses.
              </font>
              <br> <a target="_blank" href="https://openreview.net/pdf?id=wz2KvvEk44">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://anonymous.4open.science/r/SMG/">Code</a>
              &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;</span>
                        <iframe class="pdfContainer" src="https://ik.imagekit.io/xxyvnpkee/SMG_Poster.pdf?updatedAt=1755411079318#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                        <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                    </div>
                  </div>
                  </button>
            </p>
          </div>
        </div>
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="https://openreview.net/pdf?id=d7a5TpePV7" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/usb-po.png?updatedAt=1755411236242" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="https://openreview.net/pdf?id=d7a5TpePV7">How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization</a></h3>
            <p>
                <u>Hai Zhang</u>, Hang Yu, Junqiao Zhao†, Di Zhang, Chang Huang, Hongtu Zhou, Xiao Zhang, Chen Ye
                <font color="49bf9"><br><i>Annual Conference on Neural Information Processing Systems (NeurIPS) 2023</i><br></font>
              
                <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> TL;DR: 
                  We theoretically derive an optimization objective that can unify model shift and model bias and then formulate a fine-tuning process, 
                  adaptively adjusting model updates to get a performance improvement guarantee while avoiding model overfitting.
                  <br> <a target="_blank" href="https://openreview.net/pdf?id=d7a5TpePV7">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://github.com/betray12138/Unified-Model-Shift-and-Model-Bias-Policy-Optimization">Code</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;</span>
                        <iframe class="pdfContainer" src="https://ik.imagekit.io/xxyvnpkee/USB_PO_Poster.pdf?updatedAt=1755411081171#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                        <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                    </div>
                  </div>
                  </button>
            </p>
          </div>
        </div>
        <div class="list-item publication" data-category="publication">
          <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10319093" class="thumbnail"><img src="https://ik.imagekit.io/xxyvnpkee/saferl.png?updatedAt=1755411235443" alt="" /></a>
          <div class="project-description">
            <h3><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10319093">Safe Reinforcement Learning with Dead-Ends Avoidance and Recovery</a></h3>
            <p>
                Xiao Zhang, <u>Hai Zhang</u>, Hongtu Zhou, Chang Huang, Di Zhang, Chen Ye†, Junqiao Zhao†
                <font color="49bf9"><br><i>IEEE Robotics and Automation Letters (RA-L)</i><br></font>
                <font color="orange"><i>&#9733; Oral in IEEE International Conference on Robotics and Automation (ICRA) 2024 &#9733;</i></font><br>
                <font color="769fcd"> <i class="fa-solid fa-magnifying-glass"></i> TL;DR: 
                  We propose a method to construct a boundary that discriminates between safe and unsafe states. 
                  The boundary we construct is equivalent to distinguishing dead-end states, indicating the maximum extent to which safe exploration is guaranteed, and thus has a minimum limitation on exploration.
                  <br> <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10319093">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a target="_blank" href="https://github.com/tiev-tongji/dea-rrl">Code</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <button class="wechatButton">
                  <a target="_blank" href="" class="noNavigateLink">Poster</a>
                  <div class="wechatModal">
                    <div class="modal-content">
                        <span class="closeModal" style="cursor: pointer; float: left; font-size: 20px;">&times;
                          <iframe class="pdfContainer" src="https://ik.imagekit.io/xxyvnpkee/saferl_icra_poster.pdf?updatedAt=1755411078137#toolbar=0" type="application/pdf" width="1000" height="600" style="border:none;"></iframe>
                          <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
                        </span>
                    </div>
                  </div>
                  </button>
            </p>
          </div>
        </div>

        <!-- Projects -->
        <div class="list-item project" data-category="project">
          <h3>
            Some of the competitions and projects.
          </h3>
        </div>
        <div class="list-item project" data-category="project">
          <table width="100%" align="center" border="0" cellpadding="0">
            <tr>
              <td width="48%" align="center" valign="middle">
                <a target="_blank" href= "https://www.bilibili.com/video/BV17T411F7tn/?spm_id_from=333.337.search-card.all.click&vd_source=ccb4d9359e2c421512d985edb4dda337"><img src="https://ik.imagekit.io/xxyvnpkee/waic_result.jpeg?updatedAt=1755411239203" alt="prl" width="75%"> <br><br> </a>
                <p>
                  <font color="49bf9"><i> Runner-up in the WAIC: Meta-verse Lights Up Autonomous Driving, AI Simulation Driving Competition.</i></font><br>
                  An autonomous driving algorithm to achieve successfully running in simulated scenarios.</td>
                </p>
              </td>
              <td width="52%" align="center" valign="middle">
                <img src="https://ik.imagekit.io/xxyvnpkee/curling.png?updatedAt=1755411231343" alt="prl" width="48%" valign="middle"><br><br>
                <p>
                  <font color="49bf9"><i> Sixth Place in the RLChina AI Challenge - Ren Yin Spring Season <br> Curling Competition</i></font><br>
                  Fine-tune the PPO agent and combine it with the rule-based agent to tackle POMDP curling striking. </td>
                </p>
              </td>
            </tr>
          </table>
          <br><br>
          <table width="100%" align="center" border="0" cellpadding="0">
            <tr>
              <td width="38%" align="center" valign="middle">
                <img src="https://ik.imagekit.io/xxyvnpkee/shangchuang.png?updatedAt=1755411235653" alt="prl" width="80%"><br>
                <img src="https://ik.imagekit.io/xxyvnpkee/mapping.png?updatedAt=1755411232158" alt="prl" width="80%"><br><br>
                <p>
                  <font color="49bf9"><i> Unknown Environment Exploration and Application Device Based on DRL <br>
                    Innovation and Entrepreneurship Program </i></font><br>
                  Design a system to achieve real-time mapping, planning, target recognition and attacking. </td>
                </p>
              </td>
              <td width="30%" align="center" valign="middle">
                <img src="https://ik.imagekit.io/xxyvnpkee/intel_device.png?updatedAt=1755411232176" alt="prl" width="100%"><br><br>
                <img src="https://ik.imagekit.io/xxyvnpkee/intel_system.png?updatedAt=1755411232026" alt="prl" width="100%"><br><br>
                <p>
                  <font color="49bf9"><i> National Second Prize in <br> Intel Cup National College Students Embedded System Invitation Competition </i></font><br>
                  All Sight Security Eye - Intelligent Suspect Detection System. </td>
                </p>
              </td>
              <td width="2%"></td>
              <td width="30%" align="center" valign="middle">
                <img src="https://ik.imagekit.io/xxyvnpkee/patent.png?updatedAt=1755411234675" alt="prl" width="100%"><br><br>
                <p>
                  <font color="49bf9"><i> Invention Patent in submitted: Distributed Vehicle Cloudization</i></font><br>
                  Use common software engineering technique concerning distributed system and k8s to achieve a cloudization system for autonomous vehicle. </td>
                </p>
              </td>
            </tr>
          </table>
          <br>
        </div>

        <!-- CV -->
        <div class="list-item cv" data-category="cv">
          <iframe class="pdfContainer" src="https://ik.imagekit.io/xxyvnpkee/cv.pdf?updatedAt=1755414987169#toolbar=0" width="900" height="1170" style="border:none;"></iframe>
          <div class="errorMessage">Unable to display the PDF. Please try again later.</div>
        </div>

      </div>

      <div>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="blocknerf_stop()" onmouseover="blocknerf_start()">
            <td style="padding:10px;width:40%;max-width:40%;vertical-align:middle">          
              <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=b1MWjssroQuI7Qnl_jHFfFyN6qvBv7ok5qMlXjfuM24'></script>
            </td>
          </tr>
        </tbody></table>
      </div>

      <br> <br> <br>

      <!-- Footer and other elements -->
      <div id="footer">Website template adapted from <a href="https://github.com/andyzeng/andyzeng.github.io">Andy Zeng</a> and <a href="https://jonbarron.info/">Jon Barron</a>.</div>
    </div>

    <!-- JavaScript at the bottom -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
    <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>
    <script src="https://kit.fontawesome.com/1643bac768.js" crossorigin="anonymous"></script>

    <script>
      document.addEventListener("DOMContentLoaded", function() {
              // 1. 立即显示页面内容
        document.body.style.visibility = 'visible';
        document.body.style.opacity = '1';
        document.getElementById('main').style.display = 'block';

        // 2. 初始化Isotope
        const initIsotope = () => {
          // 先确保所有项目可见（供Isotope测量布局）
          $('.list-item').css('display', 'block');
          
          const $grid = $('.grid').isotope({
            itemSelector: '.list-item',
            layoutMode: 'fitRows',
            filter: '.experience', // 默认显示Experience
            initLayout: true,
            hiddenStyle: { opacity: 0, display: 'none' },  // 明确设置隐藏样式
            visibleStyle: { opacity: 1, display: 'block' }  // 明确设置显示样式
          });

          // 3. 绑定过滤按钮
          $('#filters').on('click', 'button', function() {
            const filterValue = $(this).attr('data-filter');
            $grid.isotope({ filter: filterValue });
            
            // 更新按钮状态
            $('.button-group .button').removeClass('is-checked');
            $(this).addClass('is-checked');
          });

          return $grid;
        };

        // 5. 确保依赖加载
        const initApp = () => {
          if (window.jQuery && window.Isotope) {
            const $grid = initIsotope();
            
            // 初始显示Experience
            $grid.isotope({ filter: '.experience' });
            $('#experienceButton').addClass('is-checked');

            // 初始化其他功能
            initOtherFeatures($grid);
          } else {
            setTimeout(initApp, 100);
          }
        };

        // 6. 其他功能初始化
        const initOtherFeatures = ($grid) => {
          // URL参数处理
          const queryString = window.location.search;
          const urlParams = new URLSearchParams(queryString);
          const section = urlParams.get('section'); 
          if (section) {
            const button = $(`button[data-filter='.${section}']`);
            if (button.length) button.trigger('click');
          }

          // PDF懒加载
          $('.load-pdf-button').on('click', function() {
            const $placeholder = $('.pdf-placeholder');
            const $pdfContainer = $('.pdfContainer');
            
            $placeholder.hide();
            $pdfContainer.show().attr('src', $pdfContainer.data('src'));
            
            $pdfContainer.on('error', function() {
              $pdfContainer.hide();
              $('.errorMessage').show();
            });
          });

          // ACCEPT点击效果
          $(document).on('click', function(e) {
            const $acceptText = $('<div>').addClass('accept-effect')
              .text('ACCEPT')
              .css({
                left: e.pageX + 'px',
                top: e.pageY + 'px'
              })
              .appendTo('body');
            
            setTimeout(() => $acceptText.remove(), 1000);
          });

          // 模态框处理
          $('.wechatButton').on('click', function(e) {
            e.preventDefault();
            $('.wechatModal.visible').removeClass('visible');
            $(this).find('.wechatModal').addClass('visible');
          });

          $('.closeModal').on('click', function(e) {
            e.stopPropagation();
            $(this).closest('.wechatModal').removeClass('visible');
          });

          $('.wechatModal').on('click', function(e) {
            if (e.target === this) {
              $(this).removeClass('visible');
            }
          });
        };

        // 7. 启动应用
        initApp();

      });

      // 9. 防止白屏的终极保障
      setTimeout(() => {
        if (document.body.style.visibility !== 'visible') {
          document.body.style.visibility = 'visible';
          $('.experience').css('display', 'block');
        }
      }, 3000);
    </script>
  </body>
</html>